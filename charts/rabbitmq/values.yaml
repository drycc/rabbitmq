image_org: "drycc"
image_pull_policy: "Always"
image_tag: "canary"
image_registry: "docker.io"
# limits_cpu: "100m"
# limits_memory: "50Mi"
# Configure the following ONLY if using an off-cluster rabbitmq
url: "amqp://myuser:mypassword@localhost:5672/myvhost"
# The username and password to be used by the on-cluster database.
# If left empty they will be generated using randAlphaNum
username: ""
password: ""
# GCP PDs and EBS volumes are supported only
persistence:
  enabled: false # Set to true to enable persistence
  accessMode: ReadWriteOnce
  size: 5Gi # PVC size
  ## rabbitmq data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  ## Storage class of PV to bind. By default it looks for standard storage class.
  ## If the PV uses a different storage class, specify that here.
  storageClass: ""
  volumeName: ""

global:
  # Set the location of Workflow's rabbitmq instance
  #
  # Valid values are:
  # - on-cluster: Run Rabbitmq within the Kubernetes cluster
  # - off-cluster: Run Rabbitmq outside the Kubernetes cluster (configure in rabbitmq section)
  rabbitmq_location: "on-cluster"

